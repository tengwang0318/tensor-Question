## 5.1 高效的数据输入流水线

将数据集作为Numpy的数组取出，创建batch，然后将这些batch输入到模型中用minibatch梯度下降法来训练。但效率并不高，原因如下：

* 完整的大数据集可能有几千GB，内存不够用
* 手动创建输入batch就需要手动地切分索引，可能会发生错误。
* 进行数据扩充、随机打乱每个输入的样本，会减慢模型的训练过程，因为增强过程必须在给数据提供模型之前完成。对这些操作执行并行化处理，就意味着需要担心线程同步的问题以及其他并行计算的问题。
* 将从位于CPU的主python进程中的数据输入到一个全部参数在GPU/TPU上的模型的过程包含了很多数据载入/卸载，硬件的利用率未能达到100%，完全是一种浪费。

定义**输入流水线**是一个常见的操作，可以被构建成一个提取、转换和载入的过程 **Extract, Transform and Load** ETL

### 5.1.1 输入流水线的结构

通过tf.data.Dataset对象来实现ETL

1. 提取：从数据源中读取数据，数据源可以是本地的或者云端 
2. 转换：应用变换技术来清理、扩充数据（随机切割数据、翻转、颜色扭曲、添加噪声），使其可被模型解释。通过将数据随机打乱和划分batch来完成转换。
3. 载入：将变换的数据载入更加适合训练目的的设备（GPU和CPU），然后进行训练。

### 5.1.2 tf.data.Dataset对象

tf.data.Dataset对象将一个输入流水线表示为一系列元素，以及一组作用在这些元素上的有序的变换运算。每个元素包含一个或者多个tf.Tensor对象。

根据数据的位置和格式，tf.data.Dataset类提供了多种静态方法来轻松创建数据集：

* 内存中的张量：tf.data.Dataset.from_tensors或者tf.data.Dataset.from_tensor_slice。这种情况下这些张量可以是numpy数组也可以是tf.Tensor对象。
* 从一个python生成器：tf.data.Dataset.from_generator
* 从一系列模式匹配文件中：tf.data.Dataset.list_files
* tf.data.TFRecordDataset处理TFRecord文件
* tf.data.TextLineDataset处理文本文件，以行为单位读取

一旦数据集对象被创建，它就可以通过一系列链接方式获取数据集，将其转换成一个新的tf.data.Dataset独行

tf.data.Dataset对象本身是一个iterable对象，可迭代并不意外是一个python的迭代器，可以使用python的iter关键字创建一个迭代器之后，再使用next(iterator)

```python
iterator = iter(dataset)
value = next(iterator)
```

数据集对象不仅可以从数字或数字元组中，也可以从每种python分数据结构中创建数据集

```python
import tensorflow as tf
dataset = tf.data.Dataset.from_tensor_slices({
    'a':tf.random.uniform([4]),
    'b':tf.random.uniform([4,100],maxval=100,dtype=tf.int32)
})
for value in dataset:
    print(value['b'])
```

假设定义一个产生无限数量的随机向量数据集每个向量有100个元素：

```python
import tensorflow as tf
def noise():
    while True:
        yield tf.random.uniform((100,))
dataset = tf.data.Dataset.from_generator(noise,(tf.float32))
print(dataset)

```

通过对方法对脸是调用，可以创建新的数据集对象、将刚创建的数据集进行变换、从而获取我们的ML model期望的输入数据。

假如想要对噪声向量的每个元素都+10，打乱结果，然后创建每个包含32个向量的batch：

```python
import tensorflow as tf
def noise():
    while True:
        yield tf.random.uniform((100,))
dataset = tf.data.Dataset.from_generator(noise,(tf.float32))

buffer_size, batch_size = 10, 32
dataset = dataset.map(lambda x:x+10).shuffle(buffer_size).batch(batch_size)
```

shuffle方法在每个ETL中都会使用，因为这个变换用一个固定大小的缓冲区随机打乱输入数据。该方法先从被重洗的数据中提取buffer_size个元素，然后随机打乱它们来产生输出。

batch方法就是从输入中收集batch_size个元素，然后创建一个batch作为输出。此变化的唯一约束为batch中的所有元素shape必须相同

### 5.1.3 性能优化

到目前为止，显示的tf.data.API描述里一条顺序数据输入流水线，可以将数据转换成有用的格式。这些操作都在CPU中执行，同时，模板设备（GPU、TPU）在等待数据，如果模板设备处理数据的速度比产生数据速度快就会出现目标设备的利用率为0的情况。可以通过预取技术来解决。

#### **预取**：

当一个消费者工作时，生产者不能空闲，需要在后台工作来生产下一轮迭代中的消费者需要的数据。tf.data API提供了一种prefetch(n)的方法来应用一个运行生产者和消费者工作重叠的变换。

n的选择十分容易：n时一个训练迭代中消费的元素数量，并且由于大部分模型使用数据batch进行训练，每次迭代用1个batch，因此n=1

具体操作就是：dataset.prefetch()的作用是会在第n个epoch的training的同时预先fetch第n+1个epoch的data,这个操作的实现是在background开辟一个新的线程，将数据读取在cache中，这也大大的缩减了总的训练的时间。

#### 缓存元素（没看明白）：

缓存元素被用来将数据缓存到内存中，完全不用访问数据源。这可以在使用远程文件系统时，或者读取过程中很慢时候，带来巨大的好处。如果数据能被输入进内存，只能在第一个轮结束后才能缓存数据。

任何在缓存方法前执行的运算仅执行一次，因此将这个变换放进流水线中可以带来巨大好处

#### 使用TFRecords

数据是不能直接以其在介质中存储方式读入的，这些文件需要被处理并且变化后才能正确读入。

TFRecord格式是一个二进制的与语言无关的格式，用来存储一系列二进制记录。TensorFlow可以读写由一系列tf.Example消息组成的TFRecord文件。

### 5.1.4 构建自己的数据集

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def train_dataset(batch_size=32, num_epochs=1):
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    input_x, input_y = train_x, train_y

    def scale_cn(image, label):
        return (tf.image.convert_image_dtype(image, tf.float32) - 0.5) * 2, label

    dataset = tf.data.Dataset.from_tensor_slices((tf.expand_dims(input_x, -1), tf.expand_dims(input_y, -1))).map(scale_cn)
    dataset = dataset.cache().repeat(num_epochs)
    dataset = dataset.shuffle(batch_size)

    return dataset.batch(batch_size).prefetch(1)
print(train_dataset())
```

### 5.1.5 数据扩充

数据扩充与ETL不一样，ETL仅仅对原始数据进行了变换，应用了没有改变图像内容的变换方法，而数据扩充需要在原始数据上应用有意义的转换，达成创建更大数据集的目的。

数据扩充过程包括定义一个函数，然后通过使用dataset map方法将其应用于训练集上。

下列程序是对image进行转换操作：

```python
def augment(image):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.1)
    return image
```

通过dataset map方法来将这个增强函数应用到数据集上的任务

### 5.1.6 TensorFlow数据集——tdfs

tf数据集是一个立即可用的数据集合，他可以处理ETL过程的下载和准备阶段，以及创建一个tf.data.Dataset对象

tfds不仅是将数据集下载下来和转换成标准的格式，而且在本地将数据集转换成TFRecord表示，使其存储中的读取十分搞笑，同时给使用者返回一个通过读取TFRecord生成的tf.data.Dataset对象。

Tensorflow_datasets主要有两个方法list_builders() 和 load()

list_builders()返回可用数据集列表

load(name, split)接受可用数据构建器的名字和希望的分割，分割值取决于数据构建器，因为每个数据构建器都承载着他自己的信息。

```python
import tensorflow_datasets as tfds
print(tfds.list_builders())
ds_train,ds_test = tfds.load(name='mnist',split=['train','test'])
```

只使用了一行代码就下载、处理、并将数据集转换为TFRecord，而且创建列两行tf.data.Dataset对象来读取它们

通过下列语句就可以看出数据集的信息。

```python
builder = tfds.builder('mnist')
print(builder.info)
```

输出结果：

```
tfds.core.DatasetInfo(
    name='mnist',
    version=3.0.0,
    description='The MNIST database of handwritten digits.',
    homepage='http://yann.lecun.com/exdb/mnist/',
    features=FeaturesDict({
        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=70000,
    splits={
        'test': 10000,
        'train': 60000,
    },
    supervised_keys=('image', 'label'),
    citation="""@article{lecun2010mnist,
      title={MNIST handwritten digit database},
      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},
      volume={2},
      year={2010}
    }""",
    redistribution_info=,
)
```

### 5.1.7 Keras 整合

数据集对象是由符合Keras tf.keras规范的TensorFlow实现原生支持的，这意味着当训练或者评估一个模型时，无论使用Numpy数字还是使用一个tf.data.Dataset对象，其效果都是相同的。

```python
model.compile(
							optimizer=tf.keras.optimizers.Adam(1e-5),
							loss='sparse_categorical_crossentropy',
							metrics=['accuracy'])
model.fit(train_set[num_epochs=10])				
```

TensorFlow2.0默认为eager执行模式，原生地支持通过遍历一个tf.data.Dataset对象来构建定制的训练循环。

### 5.1.8 eager整合

遍历一个数据集不仅可以使用for循环，还可以使用数据集对象来配置一个流水线。

tf.data.Dataset对象是高度优化过的，此外数据对象同tf.function能完全兼容，从而使整个训练循环可用转换成图模式进行加速，极大地缩短了代码的行数

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def make_model(n_classes):
    return tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation=tf.nn.relu),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(n_classes)
    ])


def train_dataset(batch_size=32, num_epochs=1):
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    input_x, input_y = train_x, train_y

    def scale_cn(image, label):
        return (tf.image.convert_image_dtype(image, tf.float32) - 0.5) * 2, label

    dataset = tf.data.Dataset.from_tensor_slices((tf.expand_dims(input_x, -1), tf.expand_dims(input_y, -1))).map(
        scale_cn)
    dataset = dataset.cache().repeat(num_epochs)
    dataset = dataset.shuffle(batch_size)

    return dataset.batch(batch_size).prefetch(1)


def train():
    n_classes = 10
    model = make_model(n_classes)

    dataset = train_dataset(num_epochs=10)

    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)
    step = tf.Variable(1, name='global_step')
    optimizer = tf.optimizers.Adam()
    accuracy = tf.metrics.Accuracy()

    @tf.function
    def train_step(inputs, labels):
        with tf.GradientTape() as tape:
            logits = model(inputs)
            loss_value = loss(labels, logits)
            gradients = tape.gradient(loss_value, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            step.assign_add(1)
            accuracy_value = accuracy(labels, tf.argmax(logits, -1))
            return loss_value, accuracy_value
        @tf.function
        def loop():
            for features,labels in dataset:
                loss_value,accuracy_value = train_step(features,labels)
                if tf.equal(tf.math.mod(step,10),0):
                    tf.print(step,": ",loss_value," - accuracy: ",accuracy_value)
        loop()
train()

```

## 5.2 估计器API

tf.estimator API是一个包装了机器学习流水线中重复性和标准性的高级API。

优点：

* 无须更改模型就可以在本地主机或者分布式服务器上运行基于估计器的模型。此外无须重写代码就可以在CPU、GPU或者TPU上运行基于估计器的模型。
* 估计器简化了模型开发者之间的共享模型实现。
* 可以使用更加简明、更高级的代码实现更加先进的模型。简而言之，用估计器创建模型比用底层TensorFlow API来创建模型更加简单。
* 估计器本身是用tf.keras.layers构建的，简化了定制过程。
* 估计器帮你构建图。
* 估计器提供了一个安全的分布式训练循环，可以对下面操作的时间和方式进行控制：
  * 构建图
  * 初始化变量
  * 加载数据
  * 处理异常
  * 创建检查点并从失败中恢复
  * 为TensorBoard保存summary

机器学习流水线的标准化过程流经对描述它的一个类的定义：tf.estimator.Estimator的公有方法实现

可以有两种使用估计器API的方式：构建定制的估计器，或者使用预先构建好的估计器。

预先构建好的估计器和定制的估计器遵循相同的编程模型，唯一不同是在定制估计器中使用者必须写一个model_fn函数，而预先建好的估计器不需要定义模型（以降低灵活性为代价）

估计器API包括两个组件的实现：

* 数据输入流的实现，input_fn函数的实现
* （可选项）模型的实现，处理训练、评估和预测案例，实现model_fn函数

为保证高性能，估计器API是建立在图表示之上的，即使tensorflow2.0默认是eager执行模式，model_cn 和 input_fn都不是以eager模型执行的，估计器通过这些函数切换到图模式

### 5.2.1 数据输入流水线

tf.estimator.Estimator API 将前两个阶段整合进input_fn函数的实现中，传递给train 和 evaluate方法。

input_fn函数是一个返回一个tf.data.Dataset对象的python的函数，它可以生成被模型消费的features和labels对象。

模型，连同数据集，可以处于不同的模式中，取决于我们在流水线的哪个阶段。模式是通过enum类型tf.estimator.ModeKeys实现的，包含了3个标准的键：

* TRAIN：训练模式
* EVAL：评估模式
* PREDICT：推理模式

因此可以用一个tf.estimator.ModeKeys输入变量来改变返回的数据集

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def get_input_fn(mode, batch_size=32, num_epochs=1):
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    half = test_x.shape[0] // 2
    if mode == tf.estimator.ModeKeys.TRAIN:
        input_x, input_y = train_x, train_y
        train = True
    elif mode == tf.estimator.ModeKeys.EVAL:
        input_x, input_y = test_x[:half], test_y[:num_epochs]
        train = False
    elif mode == tf.estimator.ModeKeys.PREDICT:
        input_x, input_y = test_x[half:], test_y[half:]
        train = False
    else:
        raise ValueError("tf.estimator.ModeKeys required! ")

    def scale_fn(image, label):
        return ((tf.image.convert_image_dtype(image, tf.float32) - 0.5) * 2,tf.cast(label,tf.int32))

    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((tf.expand_dims(input_x,-1),tf.expand_dims(input_y,-1))).map(scale_fn)
        if train:
            dataset = dataset.shuffle(10).repeat(num_epochs)
        dataset = dataset.batch(batch_size).prefetch(1)
        return dataset
    return input_fn
```

### 5.2.2 定制估计器

预制与定制的估计器共享一个相同的架构：他们都是为了构建一个tf.estimator.EstimatorSpec对象，该对象能够定义可被tf.estimator.Estimator运行的模型。

Model_fn函数形式：

```python
model_fn(features,labels,mode=None,params=None,config=None)
```

features是input_fn的第一个返回值

labels是input_fn的第二个返回值

mode是tf.estimator.ModeKey对象，制定了当前模型的状态，取决于它是在训练、评估还是预测状态

params是一个超参数的字典，可以被用来方便调试模型

config是一个tf.estimator.RunConfig对象，让你能够配置与运行时相关的参数



model_fn的目标有两个方面：它必须用Keras定义模型，并在多种模型下定义其行为，制定行为的方式通过返回一个正确创建的tf.estimator.EstimatorSpec来实现的

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def get_input_fn(mode, batch_size=32, num_epochs=1):
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    half = test_x.shape[0] // 2
    if mode == tf.estimator.ModeKeys.TRAIN:
        input_x, input_y = train_x, train_y
        train = True
    elif mode == tf.estimator.ModeKeys.EVAL:
        input_x, input_y = test_x[:half], test_y[:half]
        train = False
    elif mode == tf.estimator.ModeKeys.PREDICT:
        input_x, input_y = test_x[half:-1], test_y[half:-1]
        train = False
    else:
        raise ValueError("tf.estimator.ModeKeys required! ")

    def scale_fn(image, label):
        return ((tf.image.convert_image_dtype(image, tf.float32) - 0.5) * 2, tf.cast(label, tf.int32),)

    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((tf.expand_dims(input_x, -1), tf.expand_dims(input_y, -1))).map(
            scale_fn)
        if train:
            dataset = dataset.shuffle(10).repeat(num_epochs)
        dataset = dataset.batch(batch_size).prefetch(1)
        return dataset

    return input_fn


def make_model(n_classes):
    return tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation=tf.nn.relu),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(n_classes)
    ])


def model_fn(features, labels, mode):
    v1 = tf.compat.v1
    model = make_model(10)
    logits = model(features)

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = v1.argmax(logits, -1)
        return tf.estimator.EstimatorSpec(mode, predictions=predictions)
    loss = v1.reduce_mean(v1.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=v1.squeeze(labels)))

    global_step = v1.train.get_global_step()

    accuracy = v1.metrics.accuracy(labels=labels, predictions=v1.argmax(logits, -1), name='accuracy')

    metrics = {"accuracy": accuracy}
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)
    if mode == tf.estimator.ModeKeys.TRAIN:
        opt = v1.train.AdamOptimizer(1e-4)
        train_op = opt.minimize(loss, var_list=model.trainable_variables, global_step=global_step)
        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)
    raise NotImplementedError(f'Unknown mode {mode}')


print("Every log in on Tensorboard, please run tensorboard --logdir log")
estimator = tf.estimator.Estimator(model_fn, model_dir='log')
for epoch in range(50):
    print(f'Training for the {epoch}-th epoch')
    estimator.train(get_input_fn(tf.estimator.ModeKeys.TRAIN,num_epochs=1))
    print('Evaluating...')
    estimator.evaluate(get_input_fn(tf.estimator.ModeKeys.EVAL))
```

### 5.2.3 预制估计器

Tensorflow2.0有两种不同的预制估计器：

* 从Keras模型定义中自动创建的
* 构建在TF1.x API上

#### 使用一个Keras模型

tf.keras.estimator包提供了将tf.keras.Model转换成对应估计器的全部工具。当一个Keras模型得到编译后，全部的训练和评估循环就已经被定义好了

编译方法几乎已经定义好了一个类估计器的、可以被tf.keras.estimator包所使用的结果

必须定义tf.estimator.EstimatorSpec对象，这个对象定义了需要在训练和评估过程中使用的input_fn函数。但没必要之定义一个应用于两阶段EstimatorSpec对象，相反用tf.estimator.TrainSpec和tf.estimator.EvalSpec分别定义模型的行为也是可以的。

```python
train_spec = tf.estimator.TrainSpec(input_fn=get_input_fn(tf.estimator.ModeKeys.TRAIN, num_epochs=50))
eval_spec = tf.estimator.EvalSpec(input_fn=get_input_fn(tf.estimator.ModeKeys.EVAL, num_epochs=50))

model = make_model(10)
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

estimator = tf.keras.estimator.model_to_estimator(keras_model=model)
tf.estimator.train_and_evaluate(estimator,train_spec,eval_spec)
```

