## 7.1 获取数据

```python
# 用于过滤掉多个标注目标，只得到有单个标注目标掉数据集
def filter(dataset):
    return dataset.filter(lambda row: tf.equal(tf.shape(row['objects']['label'])[0], 1))
train,test ,validation = filter(train),filter(test),filter(validation)

```

## 7.2 目标定位

旨在对图像进行分类的CNN标准架构由两部分组成：特征提取器（该特征提取器产生特征向量）和一组对特征向量进行正确分类的全联接层。到目前为止：CNN仅被用于解决分类问题。

解决定位与分类问题，只是在网络上添加一个新的头，即定位头。输入数据是包含单个目标以及边界框的四个坐标的图像，因此就是通过将定位问题视为回归问题，同时使用这些信息来解决分类和定位问题。

### 7.2.1 定位是一个回归问题

将定位问题视为包含输入图像目标的边界框的四个目标的回归问题。训练CNN来解决分类任务或者回归任务之间并没有太大差别：特征提取器的架构保持不变，而将分类头变成回归头，基本思想为当存在某些输入特征时，回归头应该学会输出正确的坐标。

为了使网络学会回归目标边界框的坐标，我们必须使用损失函数来表达神经元和标签之间的输入/输出关系（即数据集中存在的边界框的四个坐标值）

L2距离可以作为损失函数，从而最小化预测值和实际值之间的距离，使其趋于0：

$L_2((x_1,y_1,x_2,y_2),(x_1^{'},y_1^{'},x_2^{'},y_2^{'}))$

```python
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import tensorflow_hub as hub

(train, test, validation), info = tfds.load('voc', split=['train', 'test', 'validation'], with_info=True)
print(info)


# 用于过滤掉多个标注目标，只得到有单个标注目标掉数据集
def filter(dataset):
    return dataset.filter(lambda row: tf.equal(tf.shape(row['objects']['label'])[0], 1))


train, test, validation = filter(train), filter(test), filter(validation)

# with tf.device('/CPU:0'):
#     for row in train.take(5):
#         obj = row['objects']
#         image = tf.image.convert_image_dtype(row['image'], tf.float32)
#
#         for idx in tf.range(tf.shape(obj['label'])[0]):
#             image = tf.squeeze(tf.image.draw_bounding_boxes(
#                 images=tf.expand_dims(image, axis=[0]),
#                 boxes=tf.reshape(obj['bbox'][idx], (1, 1, 4)),
#                 colors=tf.reshape(tf.constant((1.0, 1.0, 0, 0)), (1, 4)),
#             ),
#                 axis=[0]
#             )
#             print('label: ', info.features['objects']['label'].int2str(obj['label'][idx]))
#
#         plt.imshow(image)
#         plt.show()
inputs = tf.keras.layers.Input(shape=(299, 299, 3))
net = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4', output_shape=[2048],
                     trainable=False)(inputs)

net = tf.keras.layers.Dense(512)(net)
net = tf.keras.layers.ReLU()(net)
coordinates = tf.keras.layers.Dense(4, use_bias=False)(net)
regressor = tf.keras.Model(inputs=inputs, outputs=coordinates)


def prepare(dataset):
    def _fn(row):
        row['image'] = tf.image.convert_image_dtype(row['image'], tf.float32)
        row['image'] = tf.image.resize(row['image'], (299, 299))
        return row

    return dataset.map(_fn)


train, test, validation = prepare(train), prepare(test), prepare(validation)
```

tf.losses中可以找到对应的L2loss，与其使用tf.losses.MeanSquaredError，不如自己定义一个损失函数，因为必须强调一个细节。

如果我们决定使用已经实现的均方误差（MSE）函数，则必须考虑在底层使用tf.subtract运算。此运算仅计算左运算数与右运算数与右运算数的减法。当然，这种特性正是我们要寻找的，但是TensorFlow中的减法运算遵循NumPy的广播语义。这种特殊的语义将左侧张量的值广播到右侧张量，并且如果右侧张量的维数为1，那么左侧张量的值就会被复制。

由于我们选择的图像内部仅包含一个目标，因此bbox属性中存在一个边界框。因此，如果我们选择一个批量为32的张量，则包含边界框的张量形状为（32，1，4）.第二个位置的1可能会在损失计算时引发问题，阻碍模型收敛。

两种选择：

1. 使用Keras定义损失函数，使用tf.squeeze删除一元维度
2. 手动定义损失函数

```python

# First option -> this requires to call the loss l2, taking care of squeezing the input
# l2 = tf.losses.MeanSquaredError()
# Second option, it is the loss function itself that squeezes the input
def l2(y_true, y_pred):
    return tf.reduce_mean(
        tf.square(y_pred - tf.squeeze(y_true, axis=[1]))
    )
```



训练过程可以使用两种不同的方法来实现：

* 编写自定义训练循环(从而使用tf.GradientTape对象)
* 使用Keras模型compile和fit方法，因为这是Keras可以为我们构建标准的训练循环

但是由于希望在后面扩展此类解决方案，因此最好开始使用自定义训练循环，因为它为自定义提供了更大的自由度。

训练前要定义一个draw函数，该函数采用数据集、模型和当前步骤，并使用它们绘制真实边框和预测边框。

```python

def draw(dataset, regressor, step):
    with tf.device('/CPU"0'):
        row = next(iter(dataset.take(3).batch(3)))
        images = row['image']
        obj = row['objects']
        boxes = regressor(images)
        tf.print(boxes)
				# predict box
        images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(boxes, (-1, 1, 4)))
        # real box
        images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(obj['bbox'], (-1, 1, 4)))
        tf.summary.image('images', images, step=step)

```

1. 定义用于追踪迭代的global_step变量，然后定义用于记录训练和验证摘要的文件编写器

   ```python
   optimizer = tf.optimizers.Adam()
   epochs = 500
   batch_size = 32
   
   global_step = tf.Variable(0, trainable=False, dtype=tf.float32)
   train_writer, validation_writer = (tf.summary.create_file_writer('log/train'),
                                      tf.summary.create_file_writer('log/validation'))
   
   with validation_writer.as_default():
       draw(validation_writer)
   ```

2. 遵循TF2最佳实践，我们可以将训练步骤定义为一个函数，并使用tf.function将其转换为其图形表示形式。

   ```python
   @tf.function
   def train_step(image, coordinates):
       with tf.GradientTape() as tape:
           loss = l2(coordinates, regressor(image))
   
       gradients = tape.gradient(loss, regressor.trainable_variables)
       optimizer.apply_gradients(zip(gradients, regressor.trainable_variables))
       return loss
   ```

3. 在batches上定义训练循环，并在每次迭代时调用train_step函数：

   ```python
   train_batches = train.cache().batch(batch_size).prefetch(1)
   with train_writer.as_default():
       for _ in range(epochs):
           for batch in train_batches:
               obj = batch['objects']
               coordinates = obj['bbox']
               loss = train_step(batch['images'], coordinates)
               tf.summary.scalar('loss', loss, step=global_step)
               global_step.assign_add(1)
               if tf.equal(tf.mod(global_step, 10), 0):
                   tf.print('step: ', global_step, ' loss: ', loss)
                   with validation_writer.as_default():
                       draw(validation, regressor, global_step)
                   with train_writer.as_default():
                       draw(train, regressor, global_step)
   ```

   完整代码：

   ```python
   import tensorflow as tf
   import tensorflow_datasets as tfds
   import matplotlib.pyplot as plt
   import tensorflow_hub as hub
   import numpy as np
   
   (train, test, validation), info = tfds.load('voc', split=['train', 'test', 'validation'], with_info=True)
   print(info)
   
   
   # 用于过滤掉多个标注目标，只得到有单个标注目标掉数据集
   def filter(dataset):
       return dataset.filter(lambda row: tf.equal(tf.shape(row['objects']['label'])[0], 1))
   
   
   train, test, validation = filter(train), filter(test), filter(validation)
   #
   # with tf.device('/CPU:0'):
   #     for row in train.take(5):
   #         obj = row['objects']
   #         image = tf.image.convert_image_dtype(row['image'], tf.float32)
   #
   #         for idx in tf.range(tf.shape(obj['label'])[0]):
   #             image = tf.squeeze(tf.image.draw_bounding_boxes(
   #                 images=tf.expand_dims(image, axis=[0]),
   #                 boxes=tf.reshape(obj['bbox'][idx], (1, 1, 4)),
   #                 colors=tf.reshape(tf.constant((1.0, 1.0, 0, 0)), (1, 4)),
   #             ),
   #                 axis=[0]
   #             )
   #             print('label: ', info.features['objects']['label'].int2str(obj['label'][idx]))
   #
   #         plt.imshow(image)
   #         plt.show()
   inputs = tf.keras.layers.Input(shape=(299, 299, 3))
   net = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4', output_shape=[2048],
                        trainable=False)(inputs)
   
   net = tf.keras.layers.Dense(512)(net)
   net = tf.keras.layers.ReLU()(net)
   coordinates = tf.keras.layers.Dense(4, use_bias=False)(net)
   regressor = tf.keras.Model(inputs=inputs, outputs=coordinates)
   
   
   def prepare(dataset):
       def _fn(row):
           row['image'] = tf.image.convert_image_dtype(row['image'], tf.float32)
           row['image'] = tf.image.resize(row['image'], (299, 299))
           return row
   
       return dataset.map(_fn)
   
   
   train, test, validation = prepare(train), prepare(test), prepare(validation)
   
   
   # First option -> this requires to call the loss l2, taking care of squeezing the input
   # l2 = tf.losses.MeanSquaredError()
   # Second option, it is the loss function itself that squeezes the input
   def l2(y_true, y_pred):
       return tf.reduce_mean(
           tf.square(y_pred - tf.squeeze(y_true, axis=[1]))
       )
   
   
   def draw(dataset, regressor, step):
       with tf.device('/CPU:0'):
           row = next(iter(dataset.take(3).batch(3)))
           images = row['image']
           obj = row['objects']
           boxes = regressor(images)
           tf.print(boxes)
   
           images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(boxes, (-1, 1, 4)),
                                                 colors=np.array([ [0.0, 0.0, 1.0]]))
           images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(obj['bbox'], (-1, 1, 4)),
                                                 colors=np.array([[1.0, 0.0, 0.0]]))
           tf.summary.image('images', images, step=step)
   
   
   optimizer = tf.optimizers.Adam()
   epochs = 500
   batch_size = 32
   
   global_step = tf.Variable(0, trainable=False, dtype=tf.int64)
   train_writer, validation_writer = (tf.summary.create_file_writer('log/train'),
                                      tf.summary.create_file_writer('log/validation'))
   
   with validation_writer.as_default():
       draw(validation, regressor, global_step)
   
   
   @tf.function
   def train_step(image, coordinates):
       with tf.GradientTape() as tape:
           loss = l2(coordinates, regressor(image))
   
       gradients = tape.gradient(loss, regressor.trainable_variables)
       optimizer.apply_gradients(zip(gradients, regressor.trainable_variables))
       return loss
   
   
   train_batches = train.cache().batch(batch_size).prefetch(1)
   with train_writer.as_default():
       for _ in range(epochs):
           for batch in train_batches:
               obj = batch['objects']
               coordinates = obj['bbox']
               loss = train_step(batch['image'], coordinates)
               tf.summary.scalar('loss', loss, step=global_step)
               global_step.assign_add(1)
               if tf.equal(tf.math.mod(global_step, 10), 0):
                   tf.print('step: ', global_step, ' ~: ', loss)
                   with validation_writer.as_default():
                       draw(validation, regressor, global_step)
                   with train_writer.as_default():
                       draw(train, regressor, global_step)
   ```

   模型经过训练后不难发现在validation中的回归边界与真实边界边框不同，而训练集中的回归边界框与真实边界框相近 

   存在的问题有：

   1. 唯一测量的度量L2 loss
   2. 验证集永远不会用于测量任何数字得分
   3. 没有检查过拟合
   4. 缺乏能够在训练集和验证集上测量边界框回归优良成都的度量指标

   很明显地可以看出出现了overfit，因此需要进行正则化处理。

   ### 7.2.2 IoU
   
   IoU定义为两个区域的重叠区域与合并区域之比
   
   ​								$IoU=\frac{A\bigcap B}{A\bigcup B}$
   
   IoU值的范围在[0,1]之内，0表示不匹配，1表示完美匹配。大于0.5的IoU被认为是真阳性（匹配），而其他任何值被认为是假阳性，没有真阴性。
   
   TensorFlow实现IoU的公式非常简单，唯一需要考虑的是，由于必须以像素为单位计算面积，因此需要对坐标进行归一化。在_swap闭包中实现像素坐标的转换和更加友好的坐标转换。
   
   ```python
   def iou(pred_box, gt_box, h, w):
       """
       Compute IoU between detect box and gt boxes
       :param pred_box: shape(4,): y_min,x_min,y_max,x_max - predicted box
       :param gt_box: shape(4,): y_min,x_min,y_max,x_max - ground truth
       :param h: image height
       :param w: image width
       """
   
       def _swap(box):
           return tf.stack([box[1] * w, box[0] * h, box[3] * w, box[2] * h])
   
       pred_box = _swap(pred_box)
       gt_box = _swap(gt_box)
   
       box_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])
       area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])
       xx1 = tf.maximum(pred_box[0], gt_box[0])
       yy1 = tf.maximum(pred_box[1], gt_box[1])
       xx2 = tf.minimum(pred_box[2], gt_box[2])
       yy2 = tf.minimum(pred_box[3], gt_box[3])
   
       w, h = tf.maximum(0, xx2 - xx1), tf.maximum(0, yy2 - yy1)
       inter = w * h
       return inter / (box_area + area - inter)
   ```
   
   ### 7.2.3 平均精度
   
   如果IoU的值大于指定的阈值（通常为0.5），则可以将回归边界框视为匹配项
   
   单类预测情况下，通常在数据集上测量真阳性（TP）和假阳性（FP）的数量，平均精度如下
   
   ​									$AP=\frac{|TP|}{|TP|+|FP|}$
   
   ### 7.2.4 平均精度均值
   
   在多类检测的情况下，每个回归的边界框都可能包含一个可用类别，用于评估目标检测器性能的标准度量指标是平均精度均值（mAP）
   
   ​									$mAP=\frac{1}{|类别|}\sum_\limits{c\in类别}\frac{|TP_c|}{|FP_c|+|TP_c|}$
   
   tf2中实现mAP很简单，因为在tf.metrics包中有一个可供使用的实现。update_state方法的第一个参数是true标签，第二个参数是预测标签
   
   ```python
   m = tf.metrics.Precision()
   m.update_state([0,1,1,1],[1,0,1,1])
   print('Final result: ',m.result().numpy())
   # Final result:  0.6666667
   
   ```
   
   ### 7.2.5 改进训练脚步
   
   ```python
   threshold = 0.75
   precision_metric = tf.metrics.Precision()
   
   
   def draw(dataset, regressor, step):
       with tf.device('/CPU:0'):
           row = next(iter(dataset.take(3).batch(3)))
           images = row['image']
           obj = row['objects']
           boxes = regressor(images)
           tf.print(boxes)
   
           images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(boxes, (-1, 1, 4)),
                                                 colors=np.array([[0.0, 0.0, 1.0]]))
           images = tf.image.draw_bounding_boxes(images=images, boxes=tf.reshape(obj['bbox'], (-1, 1, 4)),
                                                 colors=np.array([[1.0, 0.0, 0.0]]))
           tf.summary.image('images', images, step=step)
   
           true_labels, predict_labels = [], []
           for idx, predict_box in enumerate(boxes):
               iou_value = iou(predict_box, tf.squeeze(obj['bbox'][idx]), 299, 299)
               true_labels.append(1)
               predict_labels.append(1 if iou_value >= threshold else 0)
           precision_metric.update_state(true_labels, predict_labels)
           tf.summary.scalar('precision', precision_metric.result(), step=step)
           
   ```
   
   ## 7.3 分类与定位
   
   如果没有关于它正在定位的目标的类别信息，被称为**候选区域网络**。可以使用单个神经网络执行目标检测与定位。在特征提取器的顶部添加第二个头并训练其图像进行分类，同时训练回归头以使边界框坐标回归。
   
   ### 7.3.1 多任务学习
   
   多任务学习是归纳传递的一种方法，它通过将相关任务的训练信号中包含的域信息作为归纳偏差来提高泛化能力。它通过使用共享表示形式并行学习任务来实现。每个任务学到的知识可以帮助更好地学习其他任务。
   
   