## 3.2 数据流图

Tensorflow使用数据流图来表示计算中各个运算之间的关系，数据流是一种编程模型，被广泛应用于并行计算。

用图来表示计算的好处：

1. **并行化**：用节点表示运算，用边表示节点之间的关系
2. **计算优化**：通过分析图来优化计算效率
3. **可移植性**：Tensorflow使用协议缓冲区--一种与语言无关、与平台无关的可扩展的序列化数据结构的机制来存储图。
4. **分布式执行**：每个图的节点可以被部署在独立的设备和不同的机器上。Tensorflow可以管理好每个节点之间的通信，并确保图的执行是正确的。

### 3.2.1 tf.Graph

定义图可以通过显式定义也可以通过隐式定义

tensorflow总是定义一个默认的tf.Graph，可以通过调用tf.get_default_graph来访问

### 3.2.2 从tf.Operation到tf.Tensor

数据流图表示的计算，节点代表计算单元，而边表示计算中消费和产生数据

**名称**唯一地标识了计算图中张量，通过调用tf.name_scope函数，我们可以为张量的名称添加prefix，从而改变其整个路径。

**类型**是tensor的数据类型，such as： tf.float32, tf.int8等

**秩**在tensorflow中表示一个张量的维数，如一个标量的秩为0，一个向量的秩为1，一个矩阵的秩为2 ......

**形状**是每个维中元素的个数

### 3.2.3 图放置——tf.device

tf.device创建一个和设备相符的上下文管理器，这个函数允许使用者请求将上下文中创建的所有运算放在相同的设备中，tf.device指定的设备不只是物理设备，还可以指定远程服务器、远程设备等。

### 3.2.4 图执行——tf.Session

tf.Session对象以具体目标的构建所定义的图为目标，是唯一能直接与硬件通信、将运算放置到指定设备上、使用本地和分布式TensorFlow运行库对象。

tf.Session对象是高度优化过的，一旦被正确地创建，它会将tf.Graph缓存起来以加速其执行。

Tf.Session的工作：

1. 通过创建tf.Session来获取资源，相当于open操作系统调用
2. 使用这些资源，等价于使用在文件描述符上使用read/write操作
3. 使用tf.Session.close来释放资源，等价于close操作

### 3.2.5 静态图中的变量

一个变量是一个对象，这个对象在图中多个sess.run调用之间维护图的状态，一个变量通过构建tf.Variable类的一个实例加入到tf.Graph中

一个变量可以由一对参数(type, shape)完全定义，通过调用tf.Variable所创建的变量可以被用作图中其他节点的输入。

与张量相比，变量有着更多的属性：一个变量对象必须被初始化，一个变量默认地被加到全局变量和可训练变量图集合中。

tf.get_variable与tf.Variable一样，tf.get_variable也可以用来创建新的变量，他们的区别在于如果变量已经定义，那么tf.get_variable的行为会有所改变。

```python
with tf.variable_scope("scope"):
	  a = tf.get_variable("v",[1]) # a.name == 'scope/v:0'
with tf.variable_scope("scope"):
  	b = tf.get_variable("v",[1]) # ValueError: Variable scope /v:0 already
with tf.variable_scope("scope",reuse = True):
  	c = tf.get_variable("v",[1]) # c.name == 'scope/v:0'
   
```

## 3.3 模型定义和训练

### 3.3.1 用tf.layers定义模型 

层模块在TensorFlow2.0已经被完全移除

### 3.3.2 自动微分——损失函数和优化器

TensorFlow使用自动微分——一个微分器是一个对象，这个对象包含了构建一个新图时，遍历每个节点时求解所需的所有规则。