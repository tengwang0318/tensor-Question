## 4.1 重新学习这个架构

1. 不再有全局变量，一个变量是否定义在一个python函数里无关紧要——他是可见的，并独立于图的其他部分
2. 不再有tf.variable_scope，在tensorflow2中，变量共享通过模型自身完成，每个模型是一个python对象，每个对象有其自己的一组的变量，只需给予相同模型的不同输入的方式来共享这些变量。
3. 不再有tf.get_variable，由于tensorflow2中每个变量与一个python变量1:1对应，不需要声明全局变量。
4. 不再有tf.layers，现在被tf.keras.layers代替。
5. 不再有全局集合

## 4.2 Keras 框架及其模型

Keras不是一个高层的机器学习框架的包装，事实上，它是一个用来定义和训练机器学习模型的API。

Keras的优点：

1. 易于使用：

   Keras结构是标准化的，每个模型的定义必须遵循通用接口，每个模型都是由层构成，每一层都是实现一个良好定义的接口

2. 模块化和可扩展性：

   Keras规范描述了一组可以用来组成任意机器学习模型的构建块，tensorflow允许你来定制组成块。

3. 原生内置：

   tensorflow2发布后，无需单独下载一个python包来使用Keras。

### 4.2.1 顺序API

tf.keras.Sequential模型可以让你通过堆叠tf.keras.layers的方式定义Keras模型

Conv2d: 28 * 28 * 1   -> 24 * 24 * 32 (动手算一下)

MaxPool2D:  24 * 24 * 32 -> 12 * 12 * 32

Conv2d: 12 * 12 * 32 -> 10 * 10 * 64

MaxPool: 10 * 10 * 64 -> 5 * 5 * 64

full connect: 5 * 5 * 64 = 1600

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist

n_class = 10
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),
    tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024, activation=tf.nn.relu),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(n_class)
])
model.summary()
(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
train_x = train_x / 255. * 2 - 1
test_x = test_x / 255. * 2 - 1
train_x = tf.expand_dims(train_x, -1).numpy()
test_x = tf.expand_dims(test_x, -1).numpy()
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']
              )
model.fit(train_x,train_y,epochs=10)
model.evaluate(test_x,test_y)
```

### 4.2.2 函数式API

函数式API可以定义多输入、多输出的模型、易于共享的层，定义残差连接，并且可以定义由任意复杂拓扑结构构成的模型。

```python
import tensorflow as tf
input_shape = (100,)
inputs = tf.keras.layers.Input(input_shape)
net = tf.keras.layers.Dense(units=64,activation=tf.nn.relu,name='fc1')(inputs)
net = tf.keras.layers.Dense(units=1,name='G')(net)
model = tf.keras.Model(inputs=inputs,outputs=net)
```

### 4.2.3子类方法

不推荐使用子类方法，因为它将层定义与使用分开了，使得重构代码时容易出错。

```python
import tensorflow as tf
class Generator(tf.keras.Model):
    def __init__(self):
        super(Generator,self).__init__()
        self.dense_1 = tf.keras.layers.Dense(units=64,activation=tf.nn.relu,name='fc1')
        self.dense_2 = tf.keras.layers.Dense(units=64,activation=tf.nn.relu,name='fc2')
        self.output = tf.keras.layers.Dense(units=1,name='G')
    def call(self, inputs):
        net = self.dense_1(inputs)
        net = self.dense_2(net)
        net = self.output(net)
        return net
```

## 4.3 eager执行模式和新特征

eager执行模式是一个重要的编程环境，它能够立即评估运算，无须建图：运算会实时返回值，而不是构建一个计算图之后再去计算。

eager执行模式有下列特点：

1. 一个更符合直觉的接口：以自然的方式组织代码并可以应用python数据结构。快速遍历小的模型和小量数据。
2. 更易调试：直接调用运算来检查运行的模型和测试变化。用标准的Python调试工具来快速报告错误。
3. 自然的控制流：使用python控制流取代图控制流，简化动态模型的配置。

### 4.3.1基本示例

```python
import tensorflow as tf

A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)
x = tf.constant([[0, 10], [0, 0.5]])
b = tf.constant([[1, -1]], dtype=tf.float32)
y = tf.add(tf.matmul(A,x),b,name = 'result')
print(y.numpy())
```

y作为一个tensor对象，可以被用到任意的tensor运算中，想要获取其值，可以调用tf.Tensor.numpy()来获取其值。

### 4.3.2函数，而不是会话

tf.Session对象已经从TensorFlow API中移除了，运算是即时的，无须在运算计算之前构建计算图。

```python
import tensorflow as tf


def multiply(x, y):
    """
    :param x:tf.Tensor a matrix
    :param y:tf.Tensor a matrix
    :return: The matrix multiplcation x @ y
    """
    assert x.shape == y.shape
    return tf.matmul(x, y)


def add(x, y):
    """
    :param x: the left hand operand.
    :param y: the right hand operand. It should be compatible with x.
    :return: x + y
    """
    return x + y


def main():
    """Main program."""
    A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)
    x = tf.constant([[0, 10], [0, 0.5]])
    b = tf.constant([[1, -1]], dtype=tf.float32)

    z = multiply(A, x)
    y = add(z, b)
    print(y)
if __name__ == '__main__':
    main()

```

### 4.3.3 不再有全局的东西

在tensorflow1中，python变量的概念和图变量的概念是强烈分割的。一个python变量是一个有着特定名字和类型的变量，遵循python的语言规则，可以通过del方法删除，并且只在他自己的命名范围和下级命名范围内可见。

图变量是一个在计算图中声明的，而且不遵循python语言规则。可以通过将其赋给一个python变量的方式声明一个图变量，但他们之间不紧密：这个变量在走出命名范围后就会被销毁，但图变量仍然存在：它是一个全局的并且持久存在的对象。

缺点：

1. 运算一旦被定义，就会一直在那里
2. 如果任何图中定义的运算有副作用，删除对应的python变量是没有用的，而副作用仍然存在（即删除变量并不能改变过去造成的不良影响
3. 即时有一个单独的有其自己python作用域的函数中声明A，x，b变量，我们仍可以从别的函数中通过获取tensor名字的方式来访问它，打破了封装。



### 4.3.4控制流

```python
import tensorflow as tf

x = tf.Variable(1, dtype=tf.int32)
y = tf.Variable(2, dtype=tf.int32)
for _ in range(5):
    y.assign_add(1)
    out = x * y
    print(out)
```

### 4.3.5 GradientTape

tf.GradientTape()创建一个记录所有自动微分运算的“磁带”

如果上下文管理器中至少有一个输入是可监控的，而且正在被监控，那么每个在上下文管理器中执行的运算都会被记录在“磁带”上

1. 它是由一个tf.Variable创建的可训练变量。
2. 它正被“磁带”监视，可以通过tf.Tensor对象的watch方法实现。

“磁带”记录了所有在上下文中执行的用于构建前向传递图的运算，这个磁带可以被展开，从而应用反向自动微分来计算梯度。

```python
import tensorflow as tf

x = tf.constant(4.0, dtype=tf.float32)
with tf.GradientTape() as tape:
    tape.watch(x)
    y = tf.pow(x, 2)
dy_dx = tape.gradient(y, x)
print(dy_dx)
```

一旦tf.GradientTape.gradient()被调用，tf.GradientTape对象就会释放它保存的全部资源。

### 4.3.6 定制训练循环

```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def make_model(n_classes):
    return tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation=tf.nn.relu),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(n_classes)
    ])


def load_data():
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    print(test_x)
    train_x = tf.expand_dims(train_x, -1)
    train_x = (tf.image.convert_image_dtype(train_x, tf.float32) - 0.5) * 2
    train_y = tf.expand_dims(train_y, -1)
    test_x = test_x / 255 * 2 - 1
    test_x = (tf.image.convert_image_dtype(test_x, tf.float32) - 0.5) * 2
    test_y = tf.expand_dims(test_y, -1)
    print(test_x)
    return (train_x, train_y), (test_x, test_y)


def train():
    n_class = 10
    model = make_model(n_class)
    (train_x, train_y), (test_x, test_y) = load_data()

    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)
    step = tf.Variable(1, name='global_step')
    optimizer = tf.optimizers.Adam()
    accuracy = tf.metrics.Accuracy()

    def train_step(inputs, labels):
        with tf.GradientTape() as tape:
            logits = model(inputs)
            loss_value = loss(labels, logits)
        gradients = tape.gradient(loss_value, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        step.assign_add(1)
        accuracy_value = accuracy(labels, tf.argmax(logits, -1))
        return loss_value, accuracy_value

    epochs = 10
    batch_size = 32
    nr_batches_train = int(train_x.shape[0] / batch_size)
    print(f"Batch size: {batch_size}")
    print(f'Number of batches per epoch: {nr_batches_train}')

    for epoch in range(epochs):
        for t in range(nr_batches_train):
            start_from = t * batch_size
            to = (t + 1) * batch_size
            features, labels = train_x[start_from:to], train_y[start_from:to]
            loss_value, accuracy_value = train_step(features, labels)
            if t % 10 == 0:
                print(f"{step.numpy()}:{loss_value}-accuracy:{accuracy_value}")
                print(f'Epoch {epoch} terminated')
if __name__ == "__main__":
    train()

```

### 4.3.7 保存和恢复模型状态

每个继承自tf.train.Checkpointable的对象都可自动序列化

在TF2.0中，整个Keras层/模型都继承自tf.train.Checkpointable，因此可以保存整个层/模型无须担心它们的变量。

保存模型的两种方法：

1. 使用检查点
2. 使用SaveModel

检查点不包含任何关于模型自身的描述，只是一种简单的存储参数并能让开发者正确恢复它的方法。此方法可以通过建立一个模型来实现，用Python的tf.Variable对象来映射检查点中保存的变量。

SaveModel格式在保存参数的数值的基础上加上了计算过程的序列化描述

1. 检查点：一种简单的在硬盘上保存变量的方法
2. SaveModel:模型结构及检查点



SaveModels是语言无关的表示方式，可以用其他语言部署，保存模型状态的作用：

1. 失败的时候重启训练过程，不浪费前面的计算。
2. 在每个训练循环的末尾保存参数，我可以用测试集测试训练的模型。
3. 将模型参数保存在不同的地方，这样可以保存能达到最佳验证性能的模型

TF2.0中可以使用两个对象来保存和恢复模型参数：

tf.train.CheckPoint是一个基于对象的序列化/反序列化器

tf.train.CheckPointManager是一个能用tf.train.CheckPoint实例来存储和管理检查点的对象。



如果想要保存一个可以检查点存储的对象，只需要将它传递给它的构造函数，或者在它的生命周期内创建一个新的对象属性就可

一旦定义了检查点对象，用它来创建一个tf.train.CheckpointManager对象，这里来指定存放模型的地点和需要保留检查点 的数量。

可训练的和非可以训练的变量都会自动加入检查点变量中来监控，允许你恢复模型并重启训练循环而避免在损失函数中引入不必要波动。优化器对象通常保留非可变变量集合（移动均值和方差）。它是一个能够用检查点保存的对象，只要加入到检查点中，就允许你在其训练过程被中断的时候以完全相同的状态重启训练循环。

### 4.3.8 总结记录和指标度量

TensorBoard仍然是TensorFlow默认和推荐的数据记录和可视化工具。tf.summary包含了所有需要的方法来保存标量、图像、直方图、分布等。

各种指标是在小批量数据上进行验证，而不是在整个训练/验证/测试集上：遍历完整的分割数据集是将数据聚合起来让我们更好地测算指标。

tf.mertics包中的对象是状态化的，这意味着它们能够聚合数据值，并在调用.result()的时候返回积累结果。



将总结记录保存到硬盘上，必须创建一个File/Summary writer对象

```python
summary_writer = tf.summary.create_file_writer(path)
```

一旦summary行计算完成之后，新的tf.summary.*能够检测到它们正在使用的上下文，并将正确的总结记录到writer中。summary writer对象通过调用.as_default()定义了一个上下文管理器，每个在上下文中调用tf.summar.*都将会把它的结果加入默认的summary writer中。

在每次训练迭代的末尾，我们可以通过调用metric对象的.update_state方法来聚合和保存在对象状态内计算的值，然后调用.result()方法。（.result()方法负责在聚合值上正确的计算指标，一旦完成计算就调用rset_states()来重置指标的内部状态，同时也可以计算其他在训练过程中计算的值）

```python
mean_loss = tf.metrics.Mean(name='loss')
```



tf.Keras.metrics.Accuracy()的用法：

其中tf.keras.metrics.Accuracy().update_state(parameter1,parameter2)计算出精度

```python
import tensorflow as tf
m = tf.keras.metrics.Accuracy()
m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]])
print(m.result().numpy())

```

Output: 0.75



```python
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist


def make_model(n_classes):
    return tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),
        tf.keras.layers.MaxPool2D((2, 2), (2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation=tf.nn.relu),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(n_classes)
    ])


def load_data():
    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
    train_x = tf.expand_dims(train_x, -1)
    train_x = (tf.image.convert_image_dtype(train_x, tf.float32) - 0.5) * 2
    train_y = tf.expand_dims(train_y, -1)
    test_x = test_x / 255 * 2 - 1
    test_x = (tf.image.convert_image_dtype(test_x, tf.float32) - 0.5) * 2
    test_y = tf.expand_dims(test_y, -1)

    return (train_x, train_y), (test_x, test_y)


def train():
    n_class = 10
    model = make_model(n_class)
    (train_x, train_y), (test_x, test_y) = load_data()

    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)
    step = tf.Variable(1, name='global_step')
    optimizer = tf.optimizers.Adam()

    ckpt = tf.train.Checkpoint(step=step, optimizer=optimizer, model=model)
    manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)
    ckpt.restore(manager.latest_checkpoint)
    if manager.latest_checkpoint:
        print(f'Restored from {manager.latest_checkpoint}')
    else:
        print("Initializing from scratch")
    accuracy = tf.metrics.Accuracy()
    mean_loss = tf.metrics.Mean(name='loss')

    def train_step(inputs, labels):
        with tf.GradientTape() as tape:
            logits = model(inputs)
            loss_value = loss(labels, logits)
        gradients = tape.gradient(loss_value, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        step.assign_add(1)
        accuracy_value = accuracy(labels, tf.argmax(logits, -1))
        return loss_value, accuracy_value

    epochs = 10
    batch_size = 32
    nr_batches_train = int(train_x.shape[0] / batch_size)
    print(f"Batch size: {batch_size}")
    print(f'Number of batches per epoch: {nr_batches_train}')

    train_summary_writer = tf.summary.create_file_writer('./log/train')
    with train_summary_writer.as_default():
        for epoch in range(epochs):
            for t in range(nr_batches_train):
                start_from = t * batch_size
                to = (t + 1) * batch_size
                features, labels = train_x[start_from:to], train_y[start_from:to]
                loss_value, accuracy_value = train_step(features, labels)
                mean_loss.update_state(loss_value)

                if t % 10 == 0:
                    print(f"{step.numpy()}:{loss_value}-accuracy:{accuracy_value}")
                    save_path = manager.save()
                    print(f'CheckPoint saved: {save_path}')
                    tf.summary.image('train_set', features, max_outputs=3, step=step.numpy())
                    print(f'Epoch {epoch} terminated')
                    tf.summary.scalar('accuracy', accuracy_value, step=step.numpy())
                    tf.summary.scalar('loss', mean_loss.result(), step=step.numpy())
                    accuracy.reset_states()
                    mean_loss.reset_states()
            print(f'Epoch{epoch} terminated')

            for t in range(nr_batches_train):
                start_from = t * batch_size
                to = (t + 1) * batch_size
                features, labels = train_x[start_from:to], train_y[start_from:to]
                logits = model(features)
                accuracy.update_state(labels, tf.argmax(logits, -1))
                print(f'Training accuracy: {accuracy.result()}')
                accuracy.reset_states()


if __name__ == "__main__":
    train()
```

eager模型无须显示地创建一个图，但并不意味着不能用Tensorflow代码来构建图。执行一个函数一次后，追踪它的行为，并将其内容转换成为图，然后回过头构建更有效率的图定义和会话执行，性能会有极大的提升。

### 4.3.9 AutoGraph

在tf2中，用@tf.function修饰某个函数时，AutoGraph将自动应用于此函数。一个函数一旦被正确的修饰，就会被tf.function和tf.autograph模块所处理，将其转换成图表示。

#### 没学明白这一部分

## 4.4 代码库迁移

没写过tf1，不学

