## 6.1获取数据

dataset.take(): create a dataset with a most count elements from dataset

dataset.skip(): create a dataset that skips count elements from this dataset

以上的两个method都是安装数据集的相对顺序进行操作的

## 6.2 迁移学习

从海量的数据中训练一个效果较好的网络对于个人来说是不太现实的，因此最明智的做法就是重复利用已训练模型的部分来解决我们的分类问题。可以将 网络从一个数据集学到的知识转移到另一个新的数据集上，从而将知识迁移。

迁移学习是指靠先前学习过的任务来学习新的任务的过程：学习过程可以更快，更准确，并且需要的训练数据更少。

所有用于分类的卷积结构都有固定的结构，可以重复利用其中的部分作为应用程序的构建块。

* 输入层：该结构旨在接受具有精确分辨率的图片。输入分辨率会影响整个架构，如果输入层分辨率高，则网络会更深
* 特征提取器：这是卷积、池化、归一化以及在输入层和第一个密集层之间的每一层网络的集合。该架构会以低维表示形式总结输入图像中包含的所有信息。
* 分类器：这些是全连接层的堆叠——一个全连接的分类器，建立在分类器提取的输入的低维表示之上。

将一个训练好的模型的知识迁移到一个新模型中，需要移除网络中特定的任务部分（即分类层），并将CNN固定为特征提取器。这种方法允许我们使用预先训练的模型特征提取器作为新分类架构的构建块。在进行迁移学习时，预训练的模型保持不变，而只有附加在特征向量上的新分类层是可训练的。

优势：

1. 可训练的参数数量很少，可以加快训练过程
2. 由于提取的特征来自不同的零用，而且训练的过程无法对其进行更改，因此可能会缓解overfit的问题

### 6.2.1 TensorFlow Hub

TensorFlow Hub是一个用于发布、发现和使用machine learning模型的可重用部分的库。模块是TensorFlow图像的一个独立部分，以及权重等。

TensorFlow Hub 上模块的URL即可创建Keras层，其中包含我们需要的模型部分。

### 6.2.4 建立模型——hub.KerasLayer

使用tensorflowhub中的模型：

1. 下载模型参数和图形描述
2. 恢复其图形中的参数
3. 创建一个包围图形的Keras层，并允许我们像使用任何其他Keras层一样使用它

```python
hub.KerasLayer("https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4", output_shape=[2048], trainable=False)
```

hub.KerasLayer函数创建hub.keras_layer.KerasLayer，它是一个tf.keras.layers.Layers对象

```python
# make a model
num_class = 5
model = tf.keras.Sequential(
    [hub.KerasLayer(
        "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4", output_shape=[2048], trainable=False),
        tf.keras.layers.Dense(512),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Dense(num_class)])
```

### 6.2.5 训练与评估

使用预先训练好的特征提取器，可以让我们在保持训练循环、损失函数和优化器不变，以及使用与每个标准分类器训练相同的结构的情况下，加快训练速度。

```python
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_hub as hub
import os

# show progress bar when we first download this model
os.environ['TFHUB_DOWNLOAD_PROGRESS'] = '1'

dataset, info = tfds.load('tf_flowers', with_info=True)
dataset = dataset['train']
print(info)
tot = 3670
train_set_size = tot // 2
validation_set_size = tot - train_set_size - train_set_size // 2
test_set_size = tot - train_set_size - validation_set_size

print('train set size: ', train_set_size)
print('validation set size: ', validation_set_size)
print('test set size: ', test_set_size)
train, test, validation = (dataset.take(train_set_size), dataset.skip(train_set_size).take(validation_set_size),
                           dataset.skip(train_set_size + validation_set_size).take(test_set_size))


# after watching info about image.dtype, should transform data_dtype
def to_float_image(example):
    example['image'] = tf.image.convert_image_dtype(example['image'], tf.float32)
    return example


# Inception architecture needs 299*299*3 input size
def resize(example):
    example['image'] = tf.image.resize(example['image'], (299, 299))
    return example


train = train.map(to_float_image).map(resize)
validation = validation.map(to_float_image).map(resize)
test = test.map(to_float_image).map(resize)

# make a model
num_class = 5
model = tf.keras.Sequential(
    [hub.KerasLayer(
        "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4", output_shape=[2048], trainable=False),
        tf.keras.layers.Dense(512),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Dense(num_class)])

# Training utilities
loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)
step = tf.Variable(1, name='global_step', trainable=False)
optimizer = tf.optimizers.Adam(1e-3)

train_summary_writer = tf.summary.create_file_writer('./log/transfer/train')
validation_summary_writer = tf.summary.create_file_writer('./log/transfer/validation')

# Metrics
accuracy = tf.metrics.Accuracy()
mean_loss = tf.metrics.Mean(name='loss')


@tf.function
def train_step(inputs, labels):
    with tf.GradientTape() as tape:
        logits = model(inputs)
        loss_value = loss(labels, logits)
    gradients = tape.gradient(loss_value, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    step.assign_add(1)

    accuracy.update_state(labels, tf.argmax(logits, -1))
    return loss_value


# configure the training set to use batches and prefetch
train = train.batch(32).prefetch(1)
validation = validation.batch(32).prefetch(1)
test = test.batch(32).prefetch(1)

num_epochs = 10
for epoch in range(num_epochs):
    for example in train:
        image, label = example['image'], example['label']
        loss_value = train_step(image, label)
        mean_loss.update_state(loss_value)

        if tf.equal(tf.math.mod(step, 10), 0):
            tf.print(step, ' loss: ', mean_loss.result(), ' accuracy: ', accuracy.result())
            mean_loss.reset_states()
            accuracy.reset_states()

    # epoch ended, measure performance on validation set
    tf.print("## VALIDATION - ", epoch)
    accuracy.reset_states()
    for example in validation:
        image, label = example['image'], example['label']
        logits = model(image)
        accuracy.update_state(label, tf.argmax(logits, -1))
    tf.print('accuracy: ',accuracy.result())
    accuracy.reset_states()
```

## 6.3 微调

微调包括通过继续反向传播对预先训练好的网络权重进行微调

### 6.3.1 何时微调

* 数据集大小：对网络进行微调意味着使用具有大量可训练参数的网络，而且具有大量参数的网络容易出现过拟合现象。如果目标数据集的大小很小，则微调网络不是一个好主意。将网络作为固定的特征提取器可能会带来更好的结果。
* 数据集的相似性：如果数据集的大小很大，并且与原始模型相似，那么对模型进行微调可能是一个好主意。稍微调整网络参数将有助于网络专门提取此数据集的特征，同时正确重用先前相似的数据集的知识

### 6.3.2 TensorFlow Hub集成

微调从TensorFlow Hub下载的模型，必须执行以下操作：

1. 下载模型参数和图标
2. 恢复图形中的模型餐忽视
3. 恢复仅在训练期间执行的所有操作
4. 将新图例添加到特征向量上
5. 将模型进行端到端到训练

将trainable改为True来实现所有目标

```python
hub.KerasLayer(
        "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4", output_shape=[2048], trainable=True)
```



